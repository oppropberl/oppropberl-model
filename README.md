# OppropBERL: A GNN and BERT-style Reinforcement Learning-based Type Inference System

Main-stream type systems do not prevent errors such as null-pointer exceptions, security problems, and concurrency errors. Optional Properties (Opprop) or pluggable type systems provide frameworks where users can guarantee a particular property holds with the help of a customizable type checker. Type annotations are used to specify a property, e.g., whether a reference can be null or not, and custom type rules enforce that property. However, manually inserting these type annotations for new and existing large projects requires a lot of human effort. Inference systems provide a constraint-based whole-program inference framework. However, thoroughly understanding the underlying framework to develop such a system is time-consuming. Furthermore, these frameworks make expensive calls to SAT and SMT solvers, which increases the runtime overhead during inference. Type system developers write test cases to ensure their type checker covers all the necessary type rules and works as expected. Our core idea is to leverage these manually written test cases along with the type checker to create a Deep Learning model to learn the type rules implicitly using a data-driven approach to automatically infer annotations for programs.

We present a novel model, OppropBERL, which takes as input a Java program to predict the appropriate type annotations for a given type system. The pre-trained Transformer model helps encode the code tokens without specifying the programming language's grammar, including the type rules. Moreover, using additional structure-aware pre-training objectives, the Graph Neural Network (GNN) better captures the semantic features of the Control Flow Graphs. In the presence of a type checker, the model can be refined further using a reinforcement learning (RL) technique. The RL agent enables the model to use a more extensive set of publicly available code (not written by the developer) to create training data artificially. The RL feedback loop reduces the effort of manually creating additional test cases, leveraging the feedback from the type checker to predict the annotations better.
